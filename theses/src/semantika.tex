\clearpage
\section{Sémantika a zpracování přirozeného jazyka}
Sémantika a zpracování přirozeného jazyka představují klíčové oblasti výzkumu v oboru počítačové lingvistiky a umělé inteligence.
Kombinace těchto oblastí je základem pro mnoho metod zabývajících se analýzou vzájemné komunikace mezi lidmi,
nebo způsobu předávání a uchovávání informací mezi člověkem a strojem.

\subsection{Sémantika}
Sémantika je vědní obor, který se zabývá zkoumáním významu.
Je to obor související s lingvistikou a logikou, jelikož jeho předmětem je analýza významu frází, slov, vět a nebo i obecně jiných symbolů,
pomocí kterých lze předávat informace.~\cite{palmer1981semantics}

Sémantiku je možné dále rozdělit do subkategorií, podle konkrétního zaměření.

Lexikální sémantika se zaměřuje na význam slov, konkrétně se zabývá studiem buďto vnitřní významové struktury slova,
nebo významové vazby, které se nacházejí v daném slovníku.~\cite{lexical-semantics}

Formální sémantika studuje význam výrazů v přirozeném jazyce pomocí matematických a logických nástrojů.
Využívá exaktně definovaných pravidel a formalismů ke zkoumání přirozeného jazyka a souvislostí mezi významem a strukturou frází.
Také se zabývá modelováním vazeb mezi jazykem, jeho strukturou, významem a informací, kterou popisuje.~\cite{rajman2007speech, portner2008formal}

Frázová sémantika (angl.~phrasal semantics) se zabývá studiem významu vět a frází především z pohledu jejich skladby a kompozice.
Hlavním předmětem je analýza toho, jak funguje skládání jednotlivých menších částí (slov či dílčích frází),
jaké jsou významy jednotlivých elementů a jak jejich složení ovlivní celkový význam fráze~\cite{riemer2010introducing-semantic}.

Analýza jednotlivých částí se většinou zaměřuje na rozlišení subjektu, predikátu a argumentu.
Subjekt většinou referuje na nějaký konkrétní objekt či entitu, predikát reprezentuje vlastnosti a události, které jsou se subjektem spojené
a argument dodává doplňující informace, jako třeba konkrétní hodnotu dané vlastnosti.~\cite{fasold2006introduction}

V kontextu výpočetní technologie a umělé inteligence existuje \enquote{výpočetní sémantika} (angl.~computational semantics).
Výpočetní sémantika je disciplína, která kombinuje znalosti z formální sémantiky, výpočetní lingvistiky a automatického odvozování znalostí.
Jejím cílem je hledání a analýza metod, které by umožnily automatické zpracování a vytváření
sémantických reprezentací pro výrazy z přirozeného jazyka a inferenční postupy.
Dále se zabývá řešením neurčitostí, analýzou komplexních frází,
vliv kontextu na význam a použití získaných znalostí pro automatické rozhodování.~\cite{computational-semantics-blackburn-bos}~\cite{computation-semantics}

\subsection{Porozumění řeči}
Porozumění řeči (angl.~spoken language understanding, SLU) označuje strojové zpracování lidské přirozené řeči na sémantické úrovni.
Jedná se tedy o extrakci významu z přirozené řeči pomocí automatických počítačových metod.
Správné určení významu promluvy je často nezbytným krokem pro mnoho běžných úloh, například interpretace požadavků či příkazů,
vyhledávání dokumentů nebo zodpovídání dotazů.~\cite{the_conversational_interface}

Přirozený lidský jazyk je velmi variabilní a stejné sdělení je možné vyjádřit v mnoha podobách, které mohou být od sebe velmi rozdílné.
Tato variabilita jazyka představuje hlavní problém, který metody porozumění řeči musí řešit.
Existuje řada metod, jakými jsou z přirozené řeči extrahovány sémantické informace pro různé typy úloh.
Následuje popis vybraných technik, které jsou široce používané v úlohách využívajících
metody porozumění přirozené řeči, jako tokenizace, bag-of-words, latentní sémantická analýza, part-of-speech tagování, nebo sémantické sítě.~\cite{the_conversational_interface}

Tato práce řeší danou problematiku expertním přístupem, konkrétně s využitím bezkontextových sémantických gramatik,
jejichž principy budou rozebrány detailněji později v samostatné sekci~\ref{subsubsec:grammars}.

\begin{enumerate}
	\item \textbf{Tokenizace}\\
	      Tokenizace bývá jedním z prvních kroků při zpracování přirozeného jazyka, kdy je vstupní text
	      rozdělen na jednotlivé diskrétní části, kterým jsou právě označovány jako \emph{tokeny}.~\cite{the_conversational_interface}

	      Častým přístupem k tokenizaci je rozdělení vstupního textu na jednotlivá slova,
	      ale existují i jiné přístupy, které používají například ještě menší jednotky~\cite{yang2024rethinking}.
	      Zatímco pro anglický nebo český jazyk je rozdělení na slova relativně přímočarý proces, pro některé jazyky,
	      které nepoužívají mezeru pro oddělení slov (např.~Japonština), může být i pouhé rozdělení na slova obtížný úkol.~\cite{the_conversational_interface}

	      Součástí tokenizace je často i proces \emph{normalizace}, který upravuje vstupní data tak, aby odpovídaly nějakým požadavkům
	      a bylo jednodušší s nimi pracovat dále.
	      Typickým příkladem normalizace může být expanze zkratek.~\cite{the_conversational_interface}

	\item \textbf{Bag-of-words}\\
	      Přístup označený jako bag-of-words je jednoduchý způsob, jak analyzovat vstupní text na relativně povrchní úrovni.
	      Tento způsob zpracování je také označovaný jako \emph{vector space model}.~\cite{the_conversational_interface}

	      Základní princip je vytvoření množiny slov ze vstupního textu a počítání jejich četností.
	      Srovnání takto získaných vektorů hodnot je pak základem pro určení míry shody dvou nebo více zdrojů.
	      Z tohoto přístupu plyne, že metoda zcela ignoruje jakékoli syntaktické informace a pořadí slov ve vstupním textu.~\cite{the_conversational_interface}

	      Její součástí je také často vyřazení slov, která nepřispívají do sémantické informace (například předložky a spojky),
	      tato vyřazená slova se označují jako \emph{stop words}.
	      Dalším častým rozšířením je \emph{lemmatizace}, což je normalizace různých tvarů slov do jedné základní podoby.
	      Výhodou přístupu bag-of-words je jeho jednoduchost a nezávislost na lingvistických znalostech.
	      Naopak nevýhodou je nízká úroveň detailu a přesnosti.~\cite{the_conversational_interface}

	\item \textbf{Latentní sémantická analýza}\\
	      Metoda latentní sémantické analýzy je podobná předchozí metodě bag-of-words ve svém základním konceptu vytvoření množiny
	      sledovaných prvků, spočítání jejich četnosti a následné práce se získaným vektorem hodnot.

	      Rozdíl oproti bag-of-words spočívá v tom, že namísto jednotlivých slov (nebo lemmat) jsou použité jejich významy a koncepty.
	      Příkladem může být sledování vzorů, kde se často v textu vyskytují stejná slova blízko sebe.~\cite{the_conversational_interface}

	      \newpage
	\item \textbf{Part-of-speech (POS) tagování}\\
	      Tento způsob zpracování přirozené řeči spočívá v přiřazení značek - \emph{tagů} - k jednotlivým slovům.
	      Tyto tagy přidávají dodatečnou informaci k daným slovům a tím tak obohacují vstupní text o sémantickou informaci.
	      Často je POS tagování také využíváno jako doplňující proces k dalším, komplexnějším způsobům zpracování sémantického textu.~\cite{the_conversational_interface}

	      Způsob realizace POS tagování může být založený na deterministických pravidlech a nebo může být proveden stochasticky.
	      Pravidlový přístup je založen na použití často velmi rozsáhlé databáze pravidel, které jsou většinou tvořené ručně lidským expertem.
	      % Proti tomu stochastický přístup využívá statistických metod pro určení pravděpodobnosti jednotlivých tagů v na daných pozicích
	      podle okolního kontextu.~\cite{the_conversational_interface}
\end{enumerate}

\subsection{Sémantické gramatiky}\label{subsubsec:grammars}
Další způsob, jakým lze zpracovat vstupní text, je založený na metodách formální syntaxe.
Celkový vstupní text lze chápat jako jeden objekt, který lze rozdělit na menší části.
Tyto menší části lze dále rekurzivně dělit až do okamžiku, než jsou jednotlivé části dále nedělitelné (atomické) - v ten moment se označují jako \emph{primitiva},
která mají funkci \emph{terminálních symbolů}.~\cite{PsutkaJ_2006_Mluvimes}

Tento proces rekurzivního dělení vytváří hierarchickou stromovou strukturu, kde kořenovým uzlem je původní vstupní text a
koncové uzly (označované jako listy) jsou tvořené právě terminálními symboly.~\cite{PsutkaJ_2006_Mluvimes}

Na Obrázku~\ref{fig:example_car_fix} je zobrazený rozklad věty
\begin{center}
	\enquote{\emph{Dobrý den, potřebuji zkontrolovat brzdy a vyměnit olej na autě, děkuji.}},
\end{center}
na kterém je možné vidět základní princip zpracování textu pomocí sémantických gramatik a výše zmíněný postupný rozklad na jednodušší jednotky.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[inner sep=2pt]
		\def\dist{15pt}
		\def\mysize{\footnotesize}

		\node[anchor=west] (dobrý den) at (0, 0) {\mysize \strut \emph{dobrý den}};
		\node[anchor=west] (potřebuji) at ($(dobrý den.east) + (\dist, 0)$) {\mysize \strut \emph{potřebuji}};
		\node[anchor=west] (zkontrolovat) at ($(potřebuji.east) + (\dist, 0)$) {\mysize \strut \emph{zkontrolovat}};
		\node[anchor=west] (brzdy) at ($(zkontrolovat.east) + (\dist, 0)$) {\mysize \strut \emph{brzdy}};
		\node[anchor=west] (a) at ($(brzdy.east) + (\dist, 0)$) {\mysize \strut \emph{a}};
		\node[anchor=west] (vyměnit) at ($(a.east) + (\dist, 0)$) {\mysize \strut \emph{vyměnit}};
		\node[anchor=west] (olej) at ($(vyměnit.east) + (\dist, 0)$) {\mysize \strut \emph{olej}};
		\node[anchor=west] (na autě) at ($(olej.east) + (\dist, 0)$) {\mysize \strut \emph{na autě}};
		\node[anchor=west] (děkuji) at ($(na autě.east) + (\dist, 0)$) {\mysize \strut \emph{děkuji}};

		\def\dist{40pt}
		\node (pozdrav) at ($(dobrý den.north) + (0, 2*\dist)$) {\mysize \texttt{\strut pozdrav}};
		\node (výplň) at ($(potřebuji.north) + (0, 2*\dist)$) {\mysize \texttt{\strut výplň}};
		\node (akce) at ($(zkontrolovat.north) + (0, \dist)$) {\mysize \texttt{\strut akce}};
		\node (předmět) at ($(brzdy.north) + (0, \dist)$) {\mysize \texttt{\strut předmět}};
		\node (výplň 2) at ($(a.north) + (0, 2*\dist)$) {\mysize \texttt{\strut výplň}};
		\node (akce 2) at ($(vyměnit.north) + (0, \dist)$) {\mysize \texttt{\strut akce}};
		\node (předmět 2) at ($(olej.north) + (0, \dist)$) {\mysize \texttt{\strut předmět}};
		\node (kontext) at ($(na autě.north) + (0, 2*\dist)$) {\mysize \texttt{\strut kontext}};
		\node (výplň 3) at ($(děkuji.north) + (0, 2*\dist)$) {\mysize \texttt{\strut výplň}};

		\draw[->] (dobrý den) -- (pozdrav);
		\draw[->] (potřebuji) -- (výplň);
		\draw[->] (zkontrolovat) -- (akce);
		\draw[->] (brzdy) -- (předmět);
		\draw[->] (a) -- (výplň 2);
		\draw[->] (vyměnit) -- (akce 2);
		\draw[->] (olej) -- (předmět 2);
		\draw[->] (na autě) -- (kontext);
		\draw[->] (děkuji) -- (výplň 3);

		\node (požadavek 1) at ($0.5*(akce.north west) + 0.5*(předmět.north east) + (0, \dist)$) {\mysize \texttt{\strut požadavek}};
		\draw[->] (akce) -- (požadavek 1);
		\draw[->] (předmět) -- (požadavek 1);

		\node (požadavek 2) at ($0.5*(akce 2.north west) + 0.5*(předmět 2.north east) + (0, \dist)$) {\mysize \texttt{\strut požadavek}};
		\draw[->] (akce 2) -- (požadavek 2);
		\draw[->] (předmět 2) -- (požadavek 2);

		\node (úvod) at ($0.5*(pozdrav.north west) + 0.5*(výplň.north east) + (2*\dist, 2*\dist)$) {\mysize \texttt{\strut úvod}};
		\draw[->] (pozdrav) -- (úvod);
		\draw[->] (výplň) -- (úvod);

		\node (obsah) at ($(výplň 2.north) + (0, 2*\dist)$) {\mysize \texttt{\strut obsah}};
		\draw[->] (požadavek 1) -- (obsah);
		\draw[->] (požadavek 2) -- (obsah);
		\draw[->] (výplň 2) -- (obsah);

		\node (závěr) at ($(kontext.north) + (-1.5*\dist, 2*\dist)$) {\mysize \texttt{\strut závěr}};
		\draw[->] (kontext) -- (závěr);
		\draw[->] (výplň 3) -- (závěr);

		\node (objednávka) at ($(obsah.north) + (0, 1*\dist)$) {\mysize \texttt{\strut objednávka}};
		\draw[->] (úvod) -- (objednávka);
		\draw[->] (obsah) -- (objednávka);
		\draw[->] (závěr) -- (objednávka);
	\end{tikzpicture}
	\caption{Ukázka rozkladu věty}\label{fig:example_car_fix}
\end{figure}


Stromová struktura umožňuje výhodně aplikovat metody pro analýzu syntaxe formálních jazyků.
Množina těchto terminální symbolů se označuje jako \emph{abeceda formálního jazyka}.
Formálním jazykem je možné popsat množinu předmětů, které jsou tvořené složením terminálních symbolů do nějaké struktury (posloupnosti, řetězce).
Tyto řetězce terminálních symbolů se označují jako \emph{slova formálního jazyka} a pravidla,
která popisují, jak je možné jednotlivé terminální symboly skládat do slov, jsou označována jako \emph{substituční} nebo \emph{produkční pravidla}.~\cite{PsutkaJ_2006_Mluvimes}


Pro lepší možnosti vyjádření jsou definované ještě takzvané \emph{neterminální symboly}, které zastávají funkci pomocných částí popisu předmětů.
Substituční pravidla mají tvar
\[
	\eta \to \omega \qquad \text{nebo} \qquad \eta \xrightarrow{P} \omega,
\]
kde $\eta$ a $\omega$ jsou řetězce terminálních a neterminálních symbolů a $P$ označuje pravděpodobnost (pro stochastická pravidla).
Substituční pravidla lze definovat i rekurzivně, což výrazně rozšiřuje vyjadřovací schopnosti a umožňuje popsat i nekonečné množiny předmětů
pomocí konečného (a relativně malého) počtu pravidel.~\cite{PsutkaJ_2006_Mluvimes}

Tato pravidla, společně s množinou terminálních a neterminálních symbolů tvoří dohromady takzvanou \emph{gramatiku}.
Formálně lze gramatiku $G$ popsat čtveřicí
\[
	G = (V_{N}, V_{T}, \rho, S),
\]
kde $V_{N}$ je množina neterminálních symbolů, $V_{T}$ je množina terminálních symbolů,
$\rho$ označuje množinu substitučních pravidel a $S \in V_{N}$ je počáteční symbol gramatiky.~\cite{PsutkaJ_2006_Mluvimes}

Konkrétní příklad ukázkové gramatiky je na Výpisu~\ref{lst:example_grammar} a k ní příslušné dva derivační stromy,
jeden pro vstupní text \enquote{\emph{malý hnědý pes spokojeně spí}} (Obrázek~\ref{fig:dog_sleep_tree})
a druhý pro vstupní text \enquote{\emph{bílý medvěd rychle a zdatně plave}} (Obrázek~\ref{fig:bear_swim_tree}).

Gramatika na Výpisu~\ref{lst:example_grammar} je ve formátu SPGF, který je představen v této práci.
V gramatice a derivačních stromech na Obrázkách~\ref{fig:dog_sleep_tree}~a~\ref{fig:bear_swim_tree} je možné vidět
použití některých dalších konceptů, jako jsou \emph{tagy} (zeleně), které nemají vliv na proces
vytváření derivačního stromu, ale přidávají do kontextu dodatečné sémantické informace.

\vspace{1cm}
\input{src/listings/grammar_example.tex}
\input{src/trees_example.tex}

Gramatiky lze rozdělit na deterministické a stochastické, podle toho, zda jsou její pravidla definována deterministicky,
nebo s využitím pravděpodobností~\cite{PsutkaJ_2006_Mluvimes}.
Tato práce se zabývá pouze deterministickým přístupem.

Takto definované gramatiky lze rozdělit do čtyř základních kategorií, podle typu jejich pravidel.
Nejobecnější a nejsložitější jsou \emph{gramatiky typu 0}, poté jsou \emph{kontextové gramatiky},
dále \emph{bezkontextové gramatiky} a nejjednodušším typem jsou \emph{regulární gramatiky}.
Schématické znázornění této hierarchie je na Obrázku~\ref{fig:chomsky}.

\begin{figure}[ht!]
	\centering
	\begin{tikzpicture}[anchor=south]
		\node[draw, ellipse, minimum width=1cm, minimum height=1.5cm] (reg) at (0, 0) {\texttt{regulární}};

		\node[draw, ellipse, minimum width=5.0cm, minimum height=2.7cm] (no) at ($(reg.south) + (0, -4pt)$) {};
		\node[anchor=center] at ($0.5*(no.north) + 0.5*(reg.north) + (0, -2pt)$) {\texttt{bezkontextové}};

		\node[draw, ellipse, minimum width=7.0cm, minimum height=3.9cm] (cont) at ($(no.south) + (0, -4pt)$) {};
		\node[anchor=center] at ($0.5*(cont.north) + 0.5*(no.north)$) {\texttt{kontextové}};

		\node[draw, ellipse, minimum width=9.0cm, minimum height=5.10cm] (type) at ($(cont.south) + (0, -4pt)$) {};
		\node[anchor=center] at ($0.5*(type.north) + 0.5*(cont.north)$) {\texttt{typu 0}};
	\end{tikzpicture}
	\caption{Schématické znázornění hierarchie formálních gramatik}\label{fig:chomsky}
\end{figure}

Se složitostí gramatiky je také spojena její vyjadřovací schopnost, tedy pomocí složitějších gramatik je možné zachytit složitější struktury.
Nejjednodušší regulární gramatiky nejsou například schopné zachytit vztah mezi částmi, které nejsou bezprostředně vedle
sebe, což je pro text s přirozeným jazykem velmi silná limitace.
Pro porozumění řeči se nejčastěji používají bezkontextové gramatiky.
Kontextové gramatiky a gramatiky typu 0 by umožňovaly zachytit ještě další složitější vazby mezi částmi
textu, ale jejich úroveň komplexnosti je natolik vysoká,
že strojové zpracování je extrémně obtížné a výpočetně náročné.~\cite{PsutkaJ_2006_Mluvimes}

Výstupem zpracování pomocí bezkontextových gramatik je tedy strukturální informace, ze které lze zjistit,
zda daný vstupní text odpovídá dané gramatice a pokud ano, jak vypadá jeho rozklad.
Takto získaná stromová struktura jednotlivých rozpoznaných symbolů představuje sémantickou informaci,
kterou je možné dále využít a zpracovat.
