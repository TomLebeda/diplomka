\subsection{Sémantické parsování pomocí gramatik}\label{subsec:moje_gramatiky}
Extrakce sémantické informace byla jednou z hlavních řešených problematik.
Jak již bylo řečeno dříve, byl zvolen přístup založený na parsování textu pomocí sémantických bezkontextových gramatik.

Při prvotních experimentech byla použita již existující implementace tohoto systému v~platformě SpeechCloud~\cite{SpeechCloud.dialog}, používající standard SRGS~\cite{srgs}.

Během těchto prvních pokusů ale bylo zjištěno, že funkcionalita, kterou nabízí existující implementace,
nebude pro potřeby této práce postačovat.
Kvůli tomu byla navržena, implementována a otestována vlastní realizace stejného konceptu
analýzy textu pomocí bezkontextových gramatik, která lépe vyhovovala ostatním zde navrženým,
realizovaným a popsaným postupům a metodám.

Detaily této vlastní implementace a rozdíly oproti existujícím variantám jsou popsány v~následujících kapitolách.

\subsubsection{Problémy s existující implementací a SRGS}
Při práci s existující implementací SRGS standardu na platformě SpeechCloud~\cite{SpeechCloud.dialog} vyvstaly následující problémy:
\begin{enumerate}
	\item \textbf{Speciální pravidlo \texttt{\$GARBAGE}}\\
	      První problém, který bylo potřeba vyřešit, byla absence pravidla \texttt{\$GARBAGE}.
	      Jedná se o speciální pravidlo definované ve standardu SRGS, které má tu vlastnost, že dokáže reprezentovat libovolnou promluvu nebo libovolný token.

	      Lze tak velmi efektivně využít v situacích, kdy je potřeba specifikovat výplňová slova,
	      která dopředu není možné odhadnout a nebo nás při analýze textu nezajímají.

	      Existující implementace však neměla toto speciální pravidlo implementováno.
	      To představovalo problém, protože možnost specifikovat libovolný token je jeden ze základních konceptů,
	      na kterém byl celý navržený koncept sémantické analýzy postaven.
	\item \textbf{Návratová datová struktura}\\
	      Existující implementace nevracela ze svého API celý derivační strom, ale pouze list tagů, které se v derivačním stromu nacházely.
	      To znamená, že byla ztracena hierarchická informace derivačního stromu spolu s informací o konkrétních pravidlech,
	      které byly během zpracování textu použité.

	      Tyto informace nebyly zcela nezbytné pro další postup, avšak jejich absence by
	      vyžadovala výrazně složitější definici parsovacích pravidel v bezkontextových gramatikách a
	      s tím samozřejmě spojený složitější systém na zpracování obdržených výsledků.

	      Dostupnost celých derivačních stromů by tedy byla výhodná ve smyslu zjednodušení dalšího postupu.
	\item \textbf{Řešení nejednoznačných situací}\\
	      Třetí problém vycházel z toho, že SRGS standard umožňuje existenci některých situací,
	      kde není jednoznačně dáno, jak má parsování probíhat,
	      a teoreticky je možné získat z jednoho vstupu více různých derivačních stromů.


	      Existující implementace tyto situace dokázala zpracovat, avšak vrátila pouze jeden výsledek,
	      který byl považovaný za nejlepší podle daného kritéria - v tomto případě podle délky zpracovaného textu.

	      Pro sémantickou analýzu textu potřebnou pro získání testovaného popisu by ale bylo výhodné,
	      kdyby bylo možné toto kritérium změnit, a nebo ještě lépe, získat všechna možná řešení.
\end{enumerate}

Po důkladném zvážení těchto problémů bylo rozhodnuto,
že jako nejlepší způsob řešení bude implementace vlastního parseru.

Během reimplementace vlastního parseru byla jako základní reference využita specifikace SRGS~\cite{srgs},
která přesně popisuje chování, funkčnost i syntax gramatik.

V průběhu reimplementace byly ovšem za účelem zjednodušení vynechány některé části SRGS standardu,
které by pro sémantickou analýzu textu v této práci nebyly nijak užitečné a naopak byly přidány nějaké funkce navíc,
které byly pak využity ve zbytku práce.

Výsledkem tak byl nový formát, označený \enquote{Semantic Parsing Grammar Format} (SPGF).
K němu byly samozřejmě vytvořené i základní softwarové nástroje, které nabízí:
\begin{itemize}
	\item kontrolu syntaxe a případné hlášení o syntaktických chybách,
	\item TreeSitter~\cite{treesitter} modul pro obarvení SPGF kódu v textových editorech,
	\item parser SPGF syntaxe s validací obsahu gramatiky i jednotlivých pravidel,
	\item parser přirozeného textu, který využívá právě SPGF gramatiky.
\end{itemize}

\subsubsection{Semantic Parsing Grammar Format (SPGF)}\label{subsubsec:spgf_def}
Základním a nejvyšším prvkem SPGF je \emph{gramatika}.
Na rozdíl od SRGS definice, SPGF gramatika nevyžaduje žádnou hlavičku a nepodporuje dodatečné prvky,
jako deklaraci jazyka nebo meta-dat.
Gramatika má podobu textového souboru, ve kterém je definována množina parsovacích pravidel.

Každé pravidlo se skládá ze svého názvu, který je uvozený symbolem \enquote{\texttt{\$}}.
Název pravidla slouží jako identifikátor, musí být tedy unikátní v dané gramatice.
Druhou částí pravidla je expanze, která reprezentuje tělo pravidla.
Mezi názvem a expanzí pravidla je znak rovnítka \enquote{=}.
Pravidlo je vždy zakončeno středníkem.
Například:
\begin{center}
	\begin{tikzpicture}
		\node[inner sep=0] (dolar) at (0, 0) {\texttt{\strut\$}};
		\node[inner sep=0,anchor=west] (name) at (dolar.east) {\texttt{\strut climbing}};
		\node[inner sep=0,anchor=west] (eq) at (name.east) {\texttt{\strut\phantom{a}=\phantom{a}}};
		\node[inner sep=0,anchor=west] (body) at (eq.east) {\texttt{\strut (leze | šplhá) [na | po]}};
		\node[inner sep=0,anchor=west] (sc) at (body.east) {\texttt{\strut;}};

		\def\downdist{0.0}
		\draw[thick, decorate, decoration={calligraphic brace, mirror, amplitude=4}]
		($(name.south west) + (0, \downdist)$) -- ($(name.south east) + (0, \downdist)$)
		node[pos=0.5, below=3pt] {\scriptsize název pravidla};
		\draw[thick, decorate, decoration={calligraphic brace, mirror, amplitude=4}]
		($(body.south west) + (0, \downdist)$) -- ($(body.south east) + (0, \downdist)$)
		node[pos=0.5, below=3pt] {\scriptsize expanze (tělo pravidla)};
	\end{tikzpicture}
\end{center}

Tělo pravidla se skládá z takzvaných \emph{alternativ}, které jsou oddělené znakem \enquote{\texttt{|}}.
Tato \emph{alternativa} je pak dále definována jako posloupnost \emph{elementů}.
V zápise má přednost mezera před \enquote{\texttt{|}}, takže několik tokenů po sobě je bráno jako jeden celek.
Element má tři varianty, může jím být \emph{token, reference} nebo \emph{sekvence}.
Například:

\begin{center}
	\begin{tikzpicture}
		\node[inner sep=0] (name) at (0, 0) {\texttt{\strut\$dog =\phantom{a}}};
		\node[inner sep=0,anchor=west] (pejsek) at (name.east) {\texttt{\strut pejsek}};
		\node[inner sep=0,anchor=west] (s) at (pejsek.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (p) at (s.east) {\texttt{\strut |}};
		\node[inner sep=0,anchor=west] (s) at (p.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (b1) at (s.east) {\texttt{\strut (}};
		\node[inner sep=0,anchor=west] (pes) at (b1.east) {\texttt{\strut pes}};
		\node[inner sep=0,anchor=west] (s) at (pes.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (p) at (s.east) {\texttt{\strut |}};
		\node[inner sep=0,anchor=west] (s) at (p.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (psík) at (s.east) {\texttt{\strut psík}};
		\node[inner sep=0,anchor=west] (b2) at (psík.east) {\texttt{\strut )}};
		\node[inner sep=0,anchor=west] (s) at (b2.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (p) at (s.east) {\texttt{\strut |}};
		\node[inner sep=0,anchor=west] (s) at (p.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (nej) at (s.east) {\texttt{\strut nejlepší}};
		\node[inner sep=0,anchor=west] (s) at (nej.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (friend) at (s.east) {\texttt{\strut přítel}};
		\node[inner sep=0,anchor=west] (s) at (friend.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (human) at (s.east) {\texttt{\strut člověka}};
		\node[inner sep=0,anchor=west] (semicolon) at (human.east) {\texttt{\strut ;}};

		\def\downdist{0.0}
		\draw[thick, decorate, decoration={calligraphic brace, mirror, amplitude=4}]
		($(pejsek.south west) + (0, \downdist)$) -- ($(pejsek.south east) + (0, \downdist)$)
		node[pos=0.5, above=-16pt] {\scriptsize alternativa 1};
		\draw[thick, decorate, decoration={calligraphic brace, mirror, amplitude=4}]
		($(b1.south west) + (0, \downdist)$) -- ($(b2.south east) + (0, \downdist)$)
		node[pos=0.5, above=-16pt] {\scriptsize alternativa 2};
		\draw[thick, decorate, decoration={calligraphic brace, mirror, amplitude=4}]
		($(nej.south west) + (0, \downdist)$) -- ($(human.south east) + (0, \downdist)$)
		node[pos=0.5, above=-16pt] {\scriptsize alternativa 3};

		\def\updist{0.1}

		\draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		($(pejsek.north west) + (0, -\updist)$) -- ($(pejsek.north east) + (0, -\updist)$)
		node[pos=0.5, above=3pt] {\scriptsize token};

		% \draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		% ($(pes.north west) + (0, -\updist)$) -- ($(pes.north east) + (0, -\updist)$)
		% node[pos=0.5, above=3pt] {\scriptsize token};

		% \draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		% ($(psík.north west) + (0, -\updist)$) -- ($(psík.north east) + (0, -\updist)$)
		% node[pos=0.5, above=3pt] {\scriptsize token};

		\draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		($(nej.north west) + (0, -\updist)$) -- ($(nej.north east) + (0, -\updist)$)
		node[pos=0.5, above=3pt] {\scriptsize token};

		\draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		($(friend.north west) + (0, -\updist)$) -- ($(friend.north east) + (0, -\updist)$)
		node[pos=0.5, above=3pt] {\scriptsize token};

		\draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		($(human.north west) + (0, -\updist)$) -- ($(human.north east) + (0, -\updist)$)
		node[pos=0.5, above=3pt] {\scriptsize token};

		\draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		($(b1.north west) + (0, -\updist)$) -- ($(b2.north east) + (0, -\updist)$)
		node[pos=0.5, above=3pt] {\scriptsize sekvence};
	\end{tikzpicture}
\end{center}

Nejjednodušší variantou \emph{elementu} je \emph{token}.
Jedná se o terminální symbol (literál), který udává, jaký řetězec je při parsování právě přípustný.
Token je možné chápat jako konkrétní slovo, které je v dané pozici v textu očekávané.
Může se skládat z jednoho nebo více znaků, která mohou být písmena, číslice, tečka, pomlčka, podtržítko nebo dvojtečka.
Součástí definice tokenu může také být (volitelně) definice opakování a případně libovolný počet tagů.
Opakování elementů a tagy budou detailněji popsány později.

Druhou variantou elementu je \emph{reference}.
Tímto pojmem se rozumí odkaz na jiné pravidlo, a nebo odkaz na nějaké speciální pravidlo s vyhrazeným názvem.
Reference začíná symbolem \enquote{\texttt{\$}} po kterém následuje okamžitě (bez mezery) jméno referovaného
pravidla definovaného ve stejné gramatice, nebo speciálního pravidla.
SPGF umožňuje referovat pravidla rekurzivně, a to jak přímo (pravidlo obsahuje referenci na samo sebe), tak v~nějakém delším cyklu.

Například jednoduchá gramatika pro (fiktivní) zápis vybraných matematických operací obsahuje rekurzivní pravidlo \texttt{\$expr}:
\begin{verbatim}
	public $expr = $numer | $expr $operator $expr;
	public $number = $digit<+>;
	public $digit = 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10;
	public $operator = plus | minus | dot | frac ;
\end{verbatim}

Formát SPGF definuje 5 speciálních pravidel s vyhraněnými jmény.
Tři z nich jsou převzaté ze SRGS standardu, zbylé dvě byly přidány navíc, aby bylo možné vynutit jistá chování parsovacího algoritmu,
která jsou v SRGS automaticky, ale v SPGF nikoli, kvůli odlišné strategii prohledávání (viz později).
\begin{enumerate}
	\item \textbf{Speciální pravidlo} \texttt{\$GARBAGE}:\\
	      Akceptuje libovolný jeden token a posune parsování o akceptovaný token dále.

	      Speciální pravidlo \texttt{\$GARBAGE} je užitečné, když je potřeba vyjádřit, že na dané pozici v textu
	      může být libovolné slovo, které buďto nedokážeme předvídat, nebo nás nezajímá.
	\item \textbf{Speciální pravidlo} \texttt{\$NULL}:\\
	      Akceptuje prázdný řetězec.
	      To znamená, že je vždy úspěšně aktivováno a nikdy neposune parsování o žádný znak dále.

	      Lze využít například pro situace, kde je žádoucí přidat do derivačního stromu (angl.~parsing tree) nějaké tagy,
	      aniž by byl učiněn postup v parsovaném textu.
	\item \textbf{Speciální pravidlo} \texttt{\$VOID}:\\
	      Vždy selže, bez ohledu na parsovaný text.
	      Nikdy tedy není úspěšné a sekvence obsahující \texttt{\$VOID} také nikdy nebude úspěšná.

	      Lze využít například pro dočasné blokování některých jiných pravidel, nebo pro zdůraznění,
	      že daná sekvence tokenů se nesmí v textu vyskytovat.
	\item \textbf{Speciální pravidlo} \texttt{\$END}:\\
	      Akceptuje konec textu.
	      Bude úspěšné právě ve chvíli, kdy je parsování na konci textu a nezbývá již žádný znak ke zpracování.

	      Umístění speciálního pravidla \texttt{\$END} na konec nějaké expanze tak způsobí,
	      že celá expanze bude úspěšná pouze ve chvíli, kdy dokáže pojmout text beze zbytku až do konce.
	\item \textbf{Speciální pravidlo} \texttt{\$BEGIN}: \\
	      Akceptuje začátek textu.
	      Bude úspěšné právě ve chvíli, kdy je parsování na začátku textu a žádný znak ještě nebyl zpracován.

	      Umístění speciálního pravidla \texttt{\$BEGIN} na začátek expanze tak způsobí,
	      že celá expanze bude úspěšná pouze ve chvíli, kdy dokáže pojmout text od prvního znaku.
\end{enumerate}

Poslední podobu, kterou \emph{element} může mít, je \emph{sekvence}.
Sekvence může být \enquote{obyčejná} nebo \enquote{volitelná}.
V~obou případech se jedná o \emph{alternativy} oddělené znakem \enquote{\texttt{|}},
list alternativ je ohraničený kulatými, respektive hranatými, závorkami.

Důvodem pro existenci \emph{sekvencí} je to, že umožňují seskupování elementů a přehlednější tvorbu složitějších konstrukcí,
podobně jako jsou v matematice používané závorky v~aritmetických či algebraických výrazech.
Volitelná sekvence (s hranatými závorkami) je pouze syntaktická zkratka pro \enquote{obyčejnou} sekvenci,
která má minimální počet opakování roven nule (takže se nemusí vůbec v textu vyskytovat) a
maximální počet opakování roven jedné.
Jedná se o obdobu operátoru \enquote{\texttt{?}} v regulárních výrazech.

Příklad zápisu pravidla s oběma typy sekvencí a jeho schématická reprezentace
je pak na Obrázku~\ref{fig:climbing_rule_scheme}.
\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\node[inner sep=0] (dolar) at (0, 0) {\texttt{\strut\$}};
		\node[inner sep=0,anchor=west] (name) at (dolar.east) {\texttt{\strut climbing}};
		\node[inner sep=0,anchor=west] (eq) at (name.east) {\texttt{\strut\phantom{a}=\phantom{a}}};
		\node[inner sep=0,anchor=west] (b1) at (eq.east) {\texttt{\strut (}};
		\node[inner sep=0,anchor=west] (s) at (b1.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (leze) at (s.east) {\texttt{\strut leze}};
		\node[inner sep=0,anchor=west] (s) at (leze.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (p) at (s.east) {\texttt{\strut |}};
		\node[inner sep=0,anchor=west] (s) at (p.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (šplhá) at (s.east) {\texttt{\strut šplhá}};
		\node[inner sep=0,anchor=west] (s) at (šplhá.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (b2) at (s.east) {\texttt{\strut )}};
		\node[inner sep=0,anchor=west] (s) at (b2.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (b3) at (s.east) {\texttt{\strut [}};
		\node[inner sep=0,anchor=west] (s) at (b3.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (na) at (s.east) {\texttt{\strut na}};
		\node[inner sep=0,anchor=west] (s) at (na.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (p) at (s.east) {\texttt{\strut |}};
		\node[inner sep=0,anchor=west] (s) at (p.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (po) at (s.east) {\texttt{\strut po}};
		\node[inner sep=0,anchor=west] (s) at (po.east) {\texttt{\strut\phantom{a}}};
		\node[inner sep=0,anchor=west] (b4) at (s.east) {\texttt{\strut ]}};
		\node[inner sep=0,anchor=west] (sem) at (b4.east) {\texttt{\strut;}};

		\def\downdist{0.0}
		\draw[thick, decorate, decoration={calligraphic brace, mirror, amplitude=4}]
		($(b1.south west) + (0, \downdist)$) -- ($(b2.south east) + (0, \downdist)$)
		node[pos=0.5, below=3pt] {\scriptsize sekvence};

		\draw[thick, decorate, decoration={calligraphic brace, mirror, amplitude=4}]
		($(b3.south west) + (0, \downdist)$) -- ($(b4.south east) + (0, \downdist)$)
		node[pos=0.5, below=3pt] {\scriptsize volitelná sekvence};

		\def\downdist{-0.1}
		\draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		($(leze.north west) + (0, \downdist)$) -- ($(šplhá.north east) + (0, \downdist)$)
		node[pos=0.5, above=3pt] {\scriptsize 2 alternativy};
		\draw[thick, decorate, decoration={calligraphic brace, amplitude=4}]
		($(na.north west) + (0, \downdist)$) -- ($(po.north east) + (0, \downdist)$)
		node[pos=0.5, above=3pt] {\scriptsize 2 alternativy};
	\end{tikzpicture}

	\phantom{a} % spacing between the pictures

	\begin{tikzpicture}[inner sep=0pt,rounded corners=2mm]
		\node[draw, minimum width=17mm] (leze) at (0, 0.6) {\texttt{\strut leze}};
		\node[draw, minimum width=17mm] (šplhá) at (0, -0.6)  {\texttt{\strut šplhá}};
		\node[circle,fill,minimum width=5pt] (begin) at ($(leze.west) + (-1, -0.6)$) {};
		\node[draw, minimum width=10mm] (na) at ($(leze) + (3, 0.0)$)  {\texttt{\strut na}};
		\node[draw, minimum width=10mm] (po) at ($(šplhá) + (3, -0.0)$)  {\texttt{\strut po}};
		\node[circle,fill,minimum width=5pt] (end) at ($(na.east) + (1.2, -0.6)$) {};

		\draw[-Stealth] (begin.center) -- ++(0.5, 0) -- ++(0, 0.6) -- (leze.west);
		\draw[-Stealth] (begin.center) -- ++(0.5, 0) -- ++(0, -0.6) -- (šplhá.west);
		\draw[-Stealth] (šplhá.east) -- ++(0.5, 0) -- ++(0, 0.6) -- ($(po.west) + (-0.5, 0.6)$) |- (po.west);
		\draw[-Stealth] (leze.east) -- ++(0.5, 0) -- ++(0, -0.6) -- ($(na.west) + (-0.5, -0.6)$) |- (na.west);
		\draw[-Stealth] ($(na.west) + (-0.7, -0.6)$) -- (end);
		\draw[-Stealth] (na.east) -| ($(na.east) + (0.5, -0.6)$) -- (end);
		\draw[-Stealth] (po.east) -| ($(po.east) + (0.5, 0.6)$) -- (end);
	\end{tikzpicture}
	\caption{Pravidlo \texttt{\$climbing} ve formátu SPGF a v podobě konečného automatu}\label{fig:climbing_rule_scheme}
\end{figure}

\subsubsection{Vstupní a výstupní body SPGF gramatiky}
Základní rozdíl v parsovací strategii SPGF oproti SRGS spočívá v tom, co je považováno za úspěšný konec parsování.
SRGS implementace jako úspěšně dokončené parsování považuje takové situace, kde poskytnutý text byl
pokryt daným pravidlem, obojí (pravidlo i text) vyčerpané (využité) beze zbytku od začátku do konce.
Naproti tomu SPGF parser nekontroluje využití celého textu, pouze celého pravidla.
Pokud tedy pravidlo pokryje pouze prvních několik slov a zbytek textu nebude \enquote{pasovat},
SRGS bude tuto situaci brát jako za neúspěch, zatímco SPGF to bude považovat za úspěch.

Dalším rozdílem mezi SRGS a SPGF je ten, že SRGS gramatiky poskytují pouze jeden vstupní bod (pravidlo označené klíčovým slovem \texttt{root}).
SPGF oproti tomu umožňuje specifikovat více pravidel jako \enquote{veřejná} klíčovým slovem \texttt{public} a tím tak gramatika bude mít více vstupních bodů.
Parser po načtení SPGF gramatiky vezme všechna pravidla označená jako \texttt{public} a pokusí se pomocí nich zpracovat poskytnutý text.
Výsledky úspěšných parsování jsou pak vrácené jako výstupy v podobě derivačních stromů, se kterými je možné dále pracovat.

Pro příklad uvažujme vstupní text: \enquote{\emph{hnědý pes utíká pryč}} a gramatiku na Výpisu~\ref{lst:simple_grammar_1}.
\input{src/listings/simple_grammar_1.tex}

Tuto gramatiku z Výpisu~\ref{lst:simple_grammar_1} lze zakreslit jako konečný automat
na Obrázku~\ref{fig:scheme_grammar_final_automata}.
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[inner sep=0pt, rounded corners=2mm]
		\node[draw, minimum width=17mm] (modrý) at (0, 1)  {\texttt{\strut modrý}};
		\node[draw, minimum width=17mm] (zelený) at (0, 0) {\texttt{\strut zelený}};
		\node[draw, minimum width=17mm] (hnědý) at (0, -1) {\texttt{\strut hnědý}};
		\node[fill, circle, minimum width=5pt] (start) at ($(zelený.west) + (-1, 0)$) {};

		\node[draw, minimum width=20mm, anchor=west] (pes) at ($(modrý.east) + (1.5, 0)$)  {\texttt{\strut pes}};
		\node[draw, minimum width=20mm, anchor=west] (míč) at ($(zelený.east) + (1.5, 0)$) {\texttt{\strut míč}};
		\node[draw, minimum width=20mm, anchor=west] (autobus) at ($(hnědý.east) + (1.5, 0)$) {\texttt{\strut autobus}};

		\node[draw, minimum width=20mm, anchor=west] (utíká) at ($(pes.east) + (3.5, 0)$)  {\texttt{\strut utíká}};
		\node[draw, minimum width=20mm, anchor=west] (jede) at ($(míč.east) + (3.5, 0)$) {\texttt{\strut jede}};
		\node[draw, minimum width=20mm, anchor=west] (kutálí) at ($(autobus.east) + (3.5, 0)$) {\texttt{\strut kutálí}};

		\node[draw, minimum width=10mm, anchor=east] (se) at ($(kutálí.west) + (-1, 0)$) {\texttt{\strut se}};

		\node[fill, circle, minimum width=5pt] (end) at ($(jede.east) + (1.1, 0)$) {};

		\draw[-Stealth] (start.center) -- ($(zelený.west) + (-0.5, 0)$) -- ($(modrý.west) + (-0.5, 0)$) -- (modrý.west);
		\draw[-Stealth] (start.center) -- ($(zelený.west) + (-0.5, 0)$) -- ($(hnědý.west) + (-0.5, 0)$) -- (hnědý.west);
		\draw[-Stealth] (start.center) -- (zelený.west);

		\draw[-Stealth] (modrý.east)
		-- ($(modrý.east) + (0.5, 0)$)
		-- ($(zelený.east) + (0.5, 0)$)
		-- ($(míč.west) + (-0.5, 0)$)
		-- ($(pes.west) + (-0.5, 0)$)
		-- (pes.west);
		\draw[-Stealth] (hnědý.east)
		-- ($(hnědý.east) + (0.5, 0)$)
		-- ($(zelený.east) + (0.5, 0)$)
		-- ($(míč.west) + (-0.5, 0)$)
		-- ($(autobus.west) + (-0.5, 0)$)
		-- (autobus.west);
		\draw[-Stealth] (zelený.east) -- (míč.west);

		\draw[-Stealth] (pes.east)
		-- ++(0.5, 0)
		-- ++(0, -1)
		-- ($(jede.west) + (-0.5, 0)$)
		-- ++(0, 1)
		-- (utíká.west);
		\draw[-Stealth] (autobus.east)
		-- ++(0.5, 0)
		-- ++(0, 1)
		-- ($(jede.west) + (-0.5, 0)$)
		-- ++(0, -1)
		-- (kutálí.west);
		\draw[-Stealth] (míč.east) -- (jede.west);
		\draw[-Stealth] ($(se.west) + (-1, 1)$)
		-- ($(se.west) + (-0.5, 1)$)
		-- ($(se.west) + (-0.5, 0)$)
		-- (se.west);
		\draw[-Stealth] (se.east) -- (kutálí.west);

		\draw[-Stealth] (jede.east) -- (end);
		\draw[-Stealth] (utíká.east) -- ++(0.5, 0) -- ++(0, -1) -- (end);
		\draw[-Stealth] (kutálí.east) -- ++(0.5, 0) -- ++(0, 1) -- (end);
	\end{tikzpicture}
	\caption{Schéma gramatiky jako konečného automatu}\label{fig:scheme_grammar_final_automata}
\end{figure}

Při zpracování textu by mohl vzniknout následující derivační strom, který je na Obrázku~\ref{fig:parsing_tree_example}:
\begin{figure}[H]
	\centering
	\begin{tikzpicture}[anchor=west,inner sep=2pt]
		\def\spacing{40pt}
		\node (w1) at (0,0) {\strut\emph{hnědý}};
		\node (w2) at ($(w1.east) + (\spacing, 0)$) {\strut\emph{pes}};
		\node (w3) at ($(w2.east) + (\spacing, 0)$) {\strut\emph{utíká}};
		\node (w4) at ($(w3.east) + (\spacing, 0)$) {\strut\emph{pryč}};
		\node[anchor=center] (n1) at ($(w1.center) + (0, \spacing)$) {\texttt{\strut\$color}};
		\node[anchor=center] (n2) at ($(w2.center) + (0, \spacing)$) {\texttt{\strut\$object}};
		\node[anchor=center] (n3) at ($(w3.center) + (0, \spacing)$) {\texttt{\strut\$action}};
		\node[anchor=center] (n4) at ($0.5*(n1.west) + 0.5*(n3.east) + (0, \spacing)$) {\texttt{\strut\$sentence}};
		\draw[->] (w1) to (n1);
		\draw[->] (w2) to (n2);
		\draw[->] (w3) to (n3);
		\draw[->] (n1) to (n4);
		\draw[->] (n2) to (n4);
		\draw[->] (n3) to (n4);
	\end{tikzpicture}
	\caption{Ukázkový derivační strom}\label{fig:parsing_tree_example}
\end{figure}

Jak je vidět, poslední slovo \enquote{\emph{pryč}} není součástí derivačního stromu,
protože parsovací pravidlo \texttt{\$sentence} jej nedokáže pokrýt.
V případě SRGS by tento derivační strom byl považovaný za neúspěch, zatímco SPGF vrátí zobrazený parsovací strom
jako úspěšný výsledek.

\subsubsection{Tagy v SPGF}
K elementům je možné přiřadit \emph{tagy}.
Každý tag je libovolný text ohraničený složenými závorkami \enquote{\texttt{\{\}}}.
Za každý element (s výjimkou speciálního pravidla \texttt{\$VOID}) je možné připsat libovolný počet těchto tagů,
oddělených mezerami.

Tagy v SPGF nijak neovlivňují parsovací proces, slouží pouze jako dodatečná informace,
kterou je možné k tokenům nebo jiným elementům přidružit.

V této práci jsou použité k tomu, aby obsahovaly dodatečnou sémantickou informaci.
V definice tagů se SPGF liší od SRGS v tom, že tagy nejsou považované za samostatné elementy a není tak možné mít například
pravidlo sestávající pouze z tagů nebo začínající tagem.
Pro situace, kdy je žádoucí začít pravidlo nějakým tagem,
je možné použít speciální pravidlo \texttt{\$NULL} a k němu přiřadit dané tagy.

Příklad gramatiky obsahující tagy je na Výpisu~\ref{lst:example_grammar_with_tags}.
K této ukázkové gramatice jsou pak na Obrázku~\ref{fig:derivacni_stromy_tagy} zobrazené tři derivační stromy pro promluvy
\enquote{\emph{pes spí}},
\enquote{\emph{kapr plave}}
a
\enquote{\emph{delfín plave}}.
Tagy jsou v derivačních stromech znázorněné zelenou barvou.

V tomto příkladu tagy přidávají informace o počtu nohou jednotlivých zvířat a jejich biologickou třídu.
Dále je pomocí tagů označeno, která činnost je klidová a která v pohybu, a která část textu je podmět a která přísudek.
Dále je možné pozorovat, že tagy jsou přiřazené pouze k nejbližšímu předchozímu elementu a distribuují se pouze přes závorky (sekvence).

\input{src/listings/tag_examples.tex}
\begin{figure}[ht!]
	\centering
	\begin{tikzpicture}[inner sep=2pt]
		\node (pes) at (0, 0) {\strut\emph{pes}};
		\node (spí) at (2.2, 0) {\strut\emph{spí}};
		\node (zvíře) at (0, 1.7) {\texttt{\$zvíře}};
		\node (činnost) at (2.2, 1.7) {\texttt{\$činnost}};
		\node (věta) at (1.1, 3.2) {\texttt{\$věta}};
		\draw[->] (pes.north) --
		node[pos=0.35, green!60!black,fill=white] {\scriptsize \texttt{nohy=4}}
		node[pos=0.65, green!60!black,fill=white] {\scriptsize \texttt{savec}}
		(zvíře.south);
		\draw[->] (spí.north) -- node[midway,green!60!black, fill=white] {\scriptsize \texttt{v klidu}} (činnost.south);
		\draw[->] (zvíře.north) -- node[midway, green!60!black,fill=white] {\scriptsize \texttt{podmět}} (věta);
		\draw[->] (činnost.north) -- node[midway, green!60!black, fill=white] {\scriptsize \texttt{přísudek}} (věta);
	\end{tikzpicture}
	\hspace{1cm}
	\begin{tikzpicture}[inner sep=2pt]
		\node (kapr) at (0, 0) {\strut\emph{kapr}};
		\node (plave) at (2.2, 0) {\strut\emph{plave}};
		\node (zvíře) at (0, 1.7) {\texttt{\$zvíře}};
		\node (činnost) at (2.2, 1.7) {\texttt{\$činnost}};
		\node (věta) at (1.1, 3.2) {\texttt{\$věta}};
		\draw[->] (kapr.north) --
		node[pos=0.35, green!60!black,fill=white] {\scriptsize \texttt{nohy=0}}
		node[pos=0.65, green!60!black,fill=white] {\scriptsize \texttt{ryba}}
		(zvíře.south);
		\draw[->] (plave.north) -- node[midway,green!60!black, fill=white] {\scriptsize \texttt{pohyb}} (činnost.south);
		\draw[->] (zvíře.north) -- node[midway, green!60!black,fill=white] {\scriptsize \texttt{podmět}} (věta);
		\draw[->] (činnost.north) -- node[midway, green!60!black, fill=white] {\scriptsize \texttt{přísudek}} (věta);
	\end{tikzpicture}
	\hspace{1cm}
	\begin{tikzpicture}[inner sep=2pt]
		\node (delfín) at (0, 0) {\strut\emph{delfín}};
		\node (plave) at (2.2, 0) {\strut\emph{plave}};
		\node (zvíře) at (0, 1.7) {\texttt{\$zvíře}};
		\node (činnost) at (2.2, 1.7) {\texttt{\$činnost}};
		\node (věta) at (1.1, 3.2) {\texttt{\$věta}};
		\draw[->] (delfín.north) --
		node[pos=0.35, green!60!black,fill=white] {\scriptsize \texttt{nohy=0}}
		node[pos=0.65, green!60!black,fill=white] {\scriptsize \texttt{savec}}
		(zvíře.south);
		\draw[->] (plave.north) -- node[midway,green!60!black, fill=white] {\scriptsize \texttt{pohyb}} (činnost.south);
		\draw[->] (zvíře.north) -- node[midway, green!60!black,fill=white] {\scriptsize \texttt{podmět}} (věta);
		\draw[->] (činnost.north) -- node[midway, green!60!black, fill=white] {\scriptsize \texttt{přísudek}} (věta);
	\end{tikzpicture}
	\caption{Derivační stromy s tagy}\label{fig:derivacni_stromy_tagy}
\end{figure}

\newpage
Syntaxe SPGF je na Výpise~\ref{lst:spgf_syntax}, detaily implementace je možné
prozkoumat ve zdrojových kódech.
\input{src/listings/spgf_syntax.tex}

\subsubsection{Parsovací strategie a opakování v SPGF}
Jak bylo zmíněno v sekci~\ref{subsubsec:spgf_def}, v gramatice je možné ke každému elementu,
s výjimkou speciálních pravidel \texttt{\$END}, \texttt{\$BEGIN}, \texttt{\$VOID} a \texttt{\$NULL},
přiřadit definici opakování.

Toto opakování udává, jaký je maximální a minimální počet bezprostředních opakování daného elementu během zpracování textu.
Například pokud má daný token specifikováno, že jeho minimální počet opakování je 2 a maximální 3,
tak v analyzovaném textu bude odpovídající slovo očekáváno dvakrát nebo třikrát po sobě.

Základní syntaxe je převzata ze standardu SRGS,
tedy dvě přirozená čísla oddělená pomlčkou (bez mezer) a ohraničené špičatými závorkami: \enquote{\texttt{<min-max>}}.
Pro pohodlnější zápis bylo definováno několik dalších alternativních
způsobů zápisu, viz Tabulka~\ref{tab:repeat_syntax}.
Pokud element žádné opakování nemá specifikované, implicitní hodnota je 1.

\begin{table}[ht!]
	\centering
	\def\width{14mm}
	\begin{tabular}{|l|p{\width}|p{\width}|l|}
		\hline
		\multirow{2}{*}{\textbf{Syntax}} & \multicolumn{2}{c|}{\textbf{Počet opakování}} & \multirow{2}{*}{\textbf{Poznámka}}                                               \\
		\cline{2-3}
		                                 & \textbf{min}                                  & \textbf{max}                       &                                             \\
		\hline
		\texttt{<m-n>}                   & $m$                                           & $n$                                & $m,n \in \mathbb{N}^{0} \ \wedge \ m\leq n$ \\
		\hline
		\texttt{<m->}                    & $m$                                           & $\infty$                           & v implementaci $\textbf{max} = 2^{32}-1$    \\
		\hline
		\texttt{<m>}                     & $m$                                           & $m$                                & ekvivalentní s \enquote{\texttt{<m-m>}}     \\
		\hline
		\texttt{<*>}                     & $0$                                           & $\infty$                           & ekvivalentní s \enquote{\texttt{<0->}}      \\
		\hline
		\texttt{<+>}                     & $1$                                           & $\infty$                           & ekvivalentní s \enquote{\texttt{<1->}}      \\
		\hline
		\texttt{<?>}                     & $0$                                           & $1$                                & ekvivalentní s \enquote{\texttt{<0-1>}}     \\
		\hline
	\end{tabular}
	\caption{Možné způsoby zápisu opakování v SPGF}\label{tab:repeat_syntax}
\end{table}

S opakovaným použitím stejného elementu je úzce spojena i strategie parsování.
Jedná se o způsob, jakým jsou řešené neurčité situace, kde je možné postupovat vícero způsoby.
Tyto situace mohou vznikat právě v místech opakování elementů, nebo tam, kde je k~dispozici vícero aplikovatelných alternativ.

Konkrétní příklad jedné z možných nejednoznačných situací (přímo převzatý ze SRGS specifikace~\cite{srgs}) je v Tabulace~\ref{tab:ambiguity_example}.
Představuje situaci, kdy dvě alternativy mají různé tagy, ale stejné tokeny a tudíž není jasné, kterou z nich použít.
\begin{table}[ht!]
	\centering
	\begin{tabular}{|l|l|}
		\hline
		Expanze            & \texttt{t1 \{tag1\} | t1 \{tag2\} | t2} \\
		Vstupní řetězec    & \texttt{t1}                             \\
		Výstup (možnost 1) & \texttt{[{t1}, \{tag1\}]}               \\
		Výstup (možnost 2) & \texttt{[{t1}, \{tag2\}]}               \\
		\hline
	\end{tabular}
	\caption{Ukázka nejednoznačnosti SRGS}\label{tab:ambiguity_example}
\end{table}

V existující implementaci SRGS, se kterou byly prováděné první experimenty, byl implementován pouze takzvaný \enquote{hladový algoritmus}, běžněji označovaný pod anglickým názvem \emph{greedy matching}.
Pro potřeby sémantické analýzy textu v této práci bylo ovšem zjištěno, že pouze \emph{greedy} algoritmus nebude zcela postačovat.

Příkladem takové situace by mohla být analýza textu
\begin{center}
	\emph{hnědý pes honí oranžovou malou veverku}
\end{center}
s cílem zjistit vlastnosti objektů (v tomto případě zvířat), zde konkrétně jejich barvy.
Pravidlo pro zachycení barvy zvířete by mohlo vypadat takto:
\begin{center}
	\texttt{public \$has\_color = \$color \$GARBAGE<*> \$animal;}
\end{center}
kde \texttt{\$color} a \texttt{\$animal} jsou reference na pravidla akceptující konkrétní slova pro barvy a zvířata.
Speciální pravidlo \texttt{\$GARBAGE} je zde definováno s operátorem opakování \enquote{\texttt{<*>}},
což lze chápat tak, že mezi samotnou barvou a zvířetem může být libovolný počet dalších slov, která nejsou podstatná.
Při zpracování textu pak ale dochází k problému, že \emph{greedy} algoritmus vrátí derivační strom zakreslený na Obrázku~\ref{fig:parsing_tree_greedy}:
\begin{figure}[ht!]
	\centering
	\begin{tikzpicture}[inner sep=2pt]
		\def\dist{70pt}
		\foreach \w [count=\wi] in {hnědý, pes, honí, oranžovou, malou, veverku}
		\node (\w) at (\wi*\dist, 0) {\emph{\strut \w}};

		\def\dist{30pt}
		\node (r1) at ($(hnědý.north) + (0, \dist)$) {\strut\texttt{\$color}};
		\node (r2) at ($(pes.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r3) at ($(honí.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r4) at ($(oranžovou.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r5) at ($(malou.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r6) at ($(veverku.north) + (0, \dist)$) {\strut\texttt{\$animal}};

		\foreach \w [count=\wi] in {hnědý, pes, honí, oranžovou, malou, veverku}
		\draw[->] (\w.north) -- (r\wi.south);

		\node (color) at ($0.5*(r1.north west) + 0.5*(r6.north east) + (0, 1.5*\dist)$) {\strut \texttt{\$has\_color}};
		\foreach \n in {1,...,6}
		\draw[->] (r\n.north) -- (color);
	\end{tikzpicture}
	\caption{Derivační strom znázorňující problém s \emph{greedy} algoritmem}\label{fig:parsing_tree_greedy}
\end{figure}

Jak je na derivačním stromu na Obrázku~\ref{fig:parsing_tree_greedy} vidět, následující sémantická analýza by došla pravděpodobně k závěru,
že v textu byla informace o hnědé veverce - což je chyba.
Zde speciální pravidlo \texttt{\$GARBAGE} s neomezeným počtem opakování v kombinaci s \emph{greedy} algoritmem způsobilo,
že toto speciální pravidlo bylo \enquote{příliš agresivní} a aktivovalo se i~v~případech, kdy by již bylo možné použít následující element.

Z tohoto důvody byla do systému implementována druhá strategie, která se běžně označuje jako \emph{lazy matching}.
Zatímco \emph{greedy} matching se v každém okamžiku snaží posunout parsování co nejdále, tato \emph{lazy} strategie se naopak snaží použít element co nejméněkrát.

Také by se dalo říci, že pokud parsovací algoritmus narazí na element $e_{1}$ následovaný elementem $e_{2}$, pak:
\begin{itemize}
	\item \emph{greedy} strategie se vždy nejdříve pokusí $e_{1}$ použít (opakovaně po sobě) a postoupí na $e_{2}$ až v moment, kdy
	      již není možné dále opakovat $e_{1}$,
	\item \emph{lazy} strategie se vždy pokusí nejdříve postoupit na element $e_{2}$ a vrátí se k $e_{1}$ pro opakované použití až v moment,
	      kdy $e_{2}$ není možné použít.
\end{itemize}

Implementace \emph{lazy} strategie umožnila zachytit sémantiku, kterou by bylo obtížné získat pomocí \emph{greedy} algoritmu.
Po několika dalších experimentech ovšem bylo zjištěno, že ani tato strategie nebude sama o sobě postačovat pro všechny potřeby sémantické analýzy.
Hlavním problémem s \emph{lazy} strategií bylo to, že v textech, kde bylo více možných vyjádření stejného typu, byla detekována vždy jen ta nejkratší.

Například předchozí úloha určování barev zvířat se vstupním textem
\begin{center}
	\emph{velký hnědý pes honí oranžovou malou veverku}
\end{center}
by mohla být zpracována SPGF pravidlem:
\begin{center}
	\texttt{public \$has\_color = \$GARBAGE<*> \$color \$GARBAGE<*> \$animal;}
\end{center}
V tomto případě bylo přidáno na začátek pravidla další \texttt{\$GARBAGE<*>}, které při použití \emph{lazy} algoritmu způsobí,
že text nemusí začínat přímo barvou, ale je možné hledat barvy a zvířata až později v textu.
Derivační strom tohoto příkladu je zakreslen na Obrázku~\ref{fig:parsing_tree_lazy}.

\begin{figure}[ht!]
	\centering
	\begin{tikzpicture}[inner sep=2pt]
		\def\dist{55pt}
		\foreach \w [count=\wi] in {velký, hnědý, pes, honí, oranžovou, malou, veverku}
		\node (\w) at (\wi*\dist, 0) {\emph{\strut \w}};

		\def\dist{30pt}
		\node (r1) at ($(velký.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r2) at ($(hnědý.north) + (0, \dist)$) {\strut\texttt{\$color}};
		\node (r3) at ($(pes.north) + (0, \dist)$) {\strut\texttt{\$animal}};

		\foreach \w [count=\wi] in {velký, hnědý, pes}
		\draw[->] (\w.north) -- (r\wi.south);

		\node (color) at ($0.5*(r1.north west) + 0.5*(r3.north east) + (0, 1.5*\dist)$) {\strut \texttt{\$has\_color}};
		\foreach \n in {1,...,3}
		\draw[->] (r\n.north) -- (color);

		\draw[thick, decorate, decoration={calligraphic brace, amplitude=5}]
		($(honí.north west) + (0, 0)$) -- ($(veverku.north east) + (0, 0)$)
		node[pos=0.5, above=4pt] {\scriptsize zbytek textu (není součástí derivačního stromu)};
	\end{tikzpicture}
	\caption{Derivační strom znázorňující problém s \emph{lazy} algoritmem}\label{fig:parsing_tree_lazy}
\end{figure}
Z derivačního stromu na Obrázku~\ref{fig:parsing_tree_lazy} je možné usoudit, že následující sémantická analýza by pravděpodobně detekovala,
že v textu se nacházela informace o hnědém psovi - to je správně.
Nicméně je dále možné pozorovat, že v textu se vyskytovala také informace o~oranžové veverce, kterou by systém nedokázal takto zachytit.

Z toho důvodu byl implementována ještě třetí strategie, která byla označena jako \enquote{\emph{thorough matching}}.
Myšlenka byla taková, že by bylo vhodné, aby algoritmus v místě nejednoznačnosti nemusel rozhodovat o tom,
který postup je nejlepší, ale aby místo toho uvažoval všechny možnosti.
Tento přístup se tedy od předchozích dvou liší v tom, že může vrátit pro jeden vstup více výstupů.

Základní koncept \emph{thorough} strategie spočívá v tom, že v místě, kde by bylo možné postupovat vícero způsoby,
je řešení rozděleno do více paralelních větví (jedna pro každou možnost) a každá větev je dále zpracovávána nezávisle.
Tímto způsobem se rekurzivně vytváří strom možných řešení, jehož listy odpovídají finálním derivačním stromům.
Po ukončení všech těchto paralelních parsování jsou úspěšné výsledky vráceny jako seznam derivačních stromů.

Na výstupu tedy bude množina všech možných způsobů, jakým bylo možné derivační strom pro dané pravidlo a vstupní text sestavit.
To následně zaručí, že během zpracování textu nebyla opomenuta žádná sémantika
(za předpokladu, že jsou expertem správně sestavena parsovací pravidla).

Například pro předchozí úlohu určování barev zvířat se vstupním textem
\begin{center}
	\emph{velký hnědý pes honí oranžovou malou veverku}
\end{center}
a SPGF pravidlem:
\begin{center}
	\texttt{public \$has\_color = \$GARBAGE<*> \$color \$GARBAGE<*> \$animal;}
\end{center}
by výstupem byly 3 derivační stromy.
Dva z nich by byly shodné s výstupem \emph{greedy} a~\emph{lazy} strategie (viz Obrázky~\ref{fig:parsing_tree_greedy} a~\ref{fig:parsing_tree_lazy}),
třetí (nový) derivační strom je na Obrázku~\ref{fig:parsing_tree_thorough}.

\begin{figure}[ht!]
	\centering
	\begin{tikzpicture}[inner sep=2pt]
		\def\dist{62pt}
		\foreach \w [count=\wi] in {velký, hnědý, pes, honí, oranžovou, malou, veverku}
		\node (\w) at (\wi*\dist, 0) {\emph{\strut \w}};

		\def\dist{30pt}
		\node (r1) at ($(velký.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r2) at ($(hnědý.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r3) at ($(pes.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r4) at ($(honí.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r5) at ($(oranžovou.north) + (0, \dist)$) {\strut\texttt{\$color}};
		\node (r6) at ($(malou.north) + (0, \dist)$) {\strut\texttt{\$GARBAGE}};
		\node (r7) at ($(veverku.north) + (0, \dist)$) {\strut\texttt{\$animal}};

		\foreach \w [count=\wi] in {velký, hnědý, pes, honí, oranžovou, malou, veverku}
		\draw[->] (\w.north) -- (r\wi.south);

		\node[ellipse] (color) at ($0.5*(r1.north west) + 0.5*(r7.north east) + (0, 1.5*\dist)$) {\strut \texttt{\$has\_color}};
		\foreach \n in {1,...,7}
		\draw[->] (r\n.north) -- (color);
	\end{tikzpicture}
	\caption{Derivační stromy z \emph{thorough} algoritmu}\label{fig:parsing_tree_thorough}
\end{figure}

Celkově by tedy z tohoto výstupu bylo možné získat informace o tom, že v textu byla hnědá veverka, hnědý pes a oranžová veverka.
Dvě z těchto informací jsou správně, pouze informace o hnědé veverce je chybná, ta se v textu nevyskytla.

Jedná se o jednu z nevýhod \emph{thorough} přístupu, že bude v textu hledat i takové informace, které z něj neplynou.
Tento problém byl vyřešen následnou filtrací získaných entit oproti referenčnímu popisu.
Detailní popis tohoto filtrování bude popsán v kapitole~\ref{subsubsec:algoritmus_zpracovani_stromu}.
% tak, že získané sémantické informace jsou porovnané s referenčním popisem obrázku a ty,
% které se v referenčním popise nevyskytují, jsou považované za falešně detekované a jsou z výstupu odstraněné
% (s výjimkou hodnot atributů, řešení chybných hodnot je popsáno v kapitole~\ref{subsec:hodnoceni}).

Tímto způsobem je pak v testovaném popisu pouze podmnožina referenčního popisu.
Jedná se o jednoduchý a efektivní způsob řešení falešně detekovaných sémantických informací.
Také ale bohužel představuje omezení v tom smyslu, že neumožňuje detekovat sémantiku, která se v textu skutečně nacházela,
ale nebyla zanesena do referenčního popisu - to klade očekávání na kvalitu referenčního popisu od experta.
Sestavení nějakého složitějšího algoritmu pro detekci falešně extrahované sémantiky představuje jedno z~možných rozšíření do budoucna.

Další nevýhodou \emph{thorough} strategie je její výpočetní náročnost.
Vzhledem k rekurzivnímu charakteru algoritmu a způsobu vytváření nových paralelních větví
se naskýtá riziko kombinatorické exploze počtu paralelních větví.
Během testování se však ukázalo, že pro moderní výpočetní techniku nepředstavují vstupy o velikosti desítek až stovek tokenů žádný problém.
Detailnější analýza výpočetní a paměťové náročnosti pro větší vstupy je nad rámec zadání a byla ponechána pro budoucí práce.

Posledním problémem, který bylo potřeba vyřešit v rámci parsovacích strategií, byl způsob, jakým strategie volit a přepínat.
V první verzi parseru se jednalo o globální přepínač, kdy bylo možné před samotným parsováním zvolit, jaká strategie má být použita.
Bylo ale zjištěno, že pro některé situace by bylo výhodné, aby bylo možné změnit výchozí strategii pro konkrétní pravidla nebo jejich části.

Například při zpracovávání číselných údajů je vhodná \emph{greedy} strategie.
Je totiž potřeba, aby posloupnost sobě jdoucí slov, které reprezentující číselný údaj, byla brána jako jeden celek.

Jiný příklad pak může být již výše zmíněný začátek pravidla \texttt{\$GARBAGE<*>},
který libovolný počet prvních slov považovat za výplň a hledat tak význam až později v textu.
Pro tuto situaci je naopak \emph{greedy} algoritmus zcela nevhodný, protože by celý text byl zpracován hned tímto počátkem.
Zde je vhodná \emph{lazy} strategie, která ve své podstatě bude dávat přednost následujícím elementům
v pravidle a tento počátek bude používat až když zbytek pravidla selže.

Z těchto důvodů byla rozšířena syntaxe pro operátor definující opakování.
Před samotné hodnoty opakování (tedy hned za otevírací špičatou závorku \enquote{\texttt{<}}) je možné napsat
jedno z písmen \texttt{L}, \texttt{G}, \texttt{T} následované dvojtečkou a poté zbytek definice opakování.
Tato písmena odpovídají jednotlivým strategiím (\emph{lazy}, \emph{greedy}, \emph{thorough}) a umožňují tak vynutit danou strategii pro dané pravidlo nebo jeho část.
Ve výsledku tak operátor opakování může vypadat například \enquote{\texttt{<G:1-3>}}, \enquote{\texttt{<L:*>}}, nebo \enquote{\texttt{<T:2->}}.
